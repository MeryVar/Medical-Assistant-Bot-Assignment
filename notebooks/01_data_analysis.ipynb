{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medical Assistant Bot - Data Analysis\n",
        "\n",
        "This notebook performs comprehensive data analysis to:\n",
        "1. Load and examine our medical conversation dataset\n",
        "2. Analyze data quality, distribution, and characteristics\n",
        "3. Determine if dataset augmentation is needed\n",
        "4. Make recommendations for preprocessing and model architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('../src')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "from dataset_loader import MedicalDatasetLoader\n",
        "from data_processor import MedicalDataProcessor\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\" All libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = MedicalDatasetLoader()\n",
        "\n",
        "print(\" Loading medical conversation dataset...\")\n",
        "data = loader.load_dataset('sample')\n",
        "synthetic_data = loader.load_dataset('synthetic')\n",
        "\n",
        "combined_data = loader.combine_datasets(['sample', 'synthetic'])\n",
        "\n",
        "print(f\"Loaded {len(data)} sample entries\")\n",
        "print(f\"Loaded {len(synthetic_data)} synthetic entries\")\n",
        "print(f\"Combined total: {len(combined_data)} entries\")\n",
        "\n",
        "df = pd.DataFrame(combined_data)\n",
        "\n",
        "print(f\"\\n Dataset Overview:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\" DATASET ADEQUACY ASSESSMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "total_entries = len(df)\n",
        "unique_categories = df['medical_category'].nunique()\n",
        "unique_conditions = df['condition'].nunique()\n",
        "\n",
        "df['input_length'] = df['input'].str.len()\n",
        "df['response_length'] = df['response'].str.len()\n",
        "avg_input_length = df['input_length'].mean()\n",
        "avg_response_length = df['response_length'].mean()\n",
        "\n",
        "print(f\"\\n1. DATASET SIZE:\")\n",
        "print(f\"   Total entries: {total_entries}\")\n",
        "print(f\"   Medical categories: {unique_categories}\")\n",
        "print(f\"   Unique conditions: {unique_conditions}\")\n",
        "\n",
        "print(f\"\\n2. TEXT QUALITY:\")\n",
        "print(f\"   Avg input length: {avg_input_length:.0f} characters\")\n",
        "print(f\"   Avg response length: {avg_response_length:.0f} characters\")\n",
        "\n",
        "needs_augmentation = total_entries < 100 or unique_categories < 5\n",
        "\n",
        "print(f\"\\n3. RECOMMENDATION:\")\n",
        "if needs_augmentation:\n",
        "    print(\"     Dataset needs augmentation for robust training\")\n",
        "    print(\"    Proceed to data augmentation phase\")\n",
        "else:\n",
        "    print(\"    Dataset adequate for initial training\")\n",
        "    print(\"    Proceed to preprocessing phase\")\n",
        "\n",
        "print(f\"\\n4. MEDICAL CATEGORY DISTRIBUTION:\")\n",
        "category_counts = df['medical_category'].value_counts()\n",
        "for category, count in category_counts.items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"   {category}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Show urgency distribution  \n",
        "print(f\"\\n5. URGENCY LEVEL DISTRIBUTION:\")\n",
        "urgency_counts = df['urgency'].value_counts()\n",
        "for urgency, count in urgency_counts.items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"   {urgency}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\n Analysis complete! Ready for next phase.\")\n",
        "print(f\" Next: {'Data Augmentation' if needs_augmentation else 'Data Preprocessing'}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
